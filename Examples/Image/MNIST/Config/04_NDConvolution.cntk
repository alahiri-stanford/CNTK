# Parameters can be overwritten on the command line
# for example: cntk configFile=myConfigFile RootDir=../.. 
# For running from Visual Studio add
# currentDirectory=$(SolutionDir)/<path to corresponding data folder> 
RootDir = ".."

ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"

deviceId = 0
# NDConvolution nodes support cudnn layout only both on GPU and CPU.
imageLayout = "cudnn"

command = train:test

precision = "float"
modelPath = "$ModelDir$/04_NDConvolution"

# uncomment the following line to write logs to a file 
stderr = "$OutputDir$/04_NDConvolution_out"
traceLevel=1
numMBsToShowResult=500

prefetch=true

#######################################
#  TRAINING CONFIG                    #
#######################################

train = [
    action = "train"

    BrainScriptNetworkBuilder = [

        // Macros
        NDConvReLULayer(inp, kW, kH, inMap, outMap, hStride, vStride, wScale, bValue) = [  // ReLU non-linearity
            convW = Parameter(outMap, kW * kH * inMap, init="uniform", initValueScale=wScale, initOnCPUOnly=false)
            conv = NDConvolution(convW, inp, (kW : kH : inMap), (1 : 1 : outMap), stride=(hStride : vStride : inMap), sharing=true, autoPadding=true, imageLayout="$imageLayout$")
            convB = ParameterTensor((1 : 1 : outMap), init="fixedValue", value=bValue)
            convPlusB = Plus(conv, convB);
            out = RectifiedLinear(convPlusB);
        ]

        NDMaxPoolLayer(inp, kW, kH, inMap, hStride, vStride) = [
            out = NDPooling(inp, (kW : kH : 1), poolKind='max', stride=(hStride : vStride : 1), autoPadding=true, imageLayout="$imageLayout$")
        ]

        DNNImageSigmoidLayer(inW, inH, inC, outDim, x, parmScale) = [
            W = ParameterTensor((outDim: inW : inH : inC), init="uniform", initValueScale=parmScale)
            b = LearnableParameter(outDim, 1,              init="uniform", initValueScale=parmScale) 
            t = Times(W, x)
            z = Plus(t, b)
            out = Sigmoid(z)
        ]

        DNNLayer(inDim, outDim, x, parmScale) = [               // no non-linearity, as input for SoftMax
            W = Parameter(outDim, inDim, init="uniform", initValueScale=parmScale, initOnCPUOnly=false)
            b = Parameter(outDim, 1,     init="uniform", initValueScale=parmScale, initOnCPUOnly=false)
            t = Times(W, x)
            out = Plus(t, b)
        ]

        // Network
        imageW = 28
        imageH = 28
        labelDim = 10

        features = ImageInput(imageW, imageH, 1, imageLayout="$imageLayout$", tag="feature")
        featScale = Constant(0.00390625)
        featScaled = Scale(featScale, features)
        labels = Input(labelDim, tag="label")

        # conv1
        kW1 = 5
        kH1 = 5
        cMap1 = 16
        hStride1 = 1
        vStride1 = 1
        conv1 = NDConvReLULayer(featScaled, kW1, kH1, 1, cMap1, hStride1, vStride1, 10, 1).out

        pool1W = 2
        pool1H = 2
        pool1hStride = 2
        pool1vStride = 2
        pool1 = NDMaxPoolLayer(conv1, pool1W, pool1H, cMap1, pool1hStride, pool1vStride).out

        # conv2
        kW2 = 5
        kH2 = 5
        cMap2 = 32
        hStride2 = 1
        vStride2 = 1
        conv2 = NDConvReLULayer(pool1, kW2, kH2, cMap1, cMap2, hStride2, vStride2, 10, 1).out

        pool2W = 2
        pool2H = 2
        pool2hStride = 2
        pool2vStride = 2
        pool2 = NDMaxPoolLayer(conv2, pool2W, pool2H, cMap2, pool2hStride, pool2vStride).out

        h1Dim = 128
        # DNNSigmoidLayer and DNNLayer are defined in Macros.ndl
        h1 = DNNImageSigmoidLayer(7, 7, cMap2, h1Dim, pool2, 1).out
        ol = DNNLayer(h1Dim, labelDim, h1, 1).out

        ce = CrossEntropyWithSoftmax(labels, ol, tag="criterion")
        err = ErrorPrediction(labels, ol, tag="eval")
        outputNodes = ol
    ]
    
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerMB = 0.1
        momentumPerMB = 0*10:0.7
        maxEpochs = 15
    ]
    
    reader = [
        readerType = "UCIFastReader"
        # To get the data (Train-28x28.txt) please run `python mnist_convert.py` 
        # from the 'AdditionalFiles' folder. See REAMDE.md for details.
        file = "$DataDir$/Train-28x28.txt"
        
        features = [
            dim = 784
            start = 1
        ]
        
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]    
]

#######################################
#  TEST CONFIG                        #
#######################################

test = [
    action = test
    minibatchSize = 16
    
    reader = [
        readerType = "UCIFastReader"
        file = "$DataDir$/Test-28x28.txt"
        
        features = [
            dim = 784
            start = 1
        ]
        
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]
]
